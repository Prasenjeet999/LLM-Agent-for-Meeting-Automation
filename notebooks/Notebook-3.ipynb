{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meeting Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/r2n9ckp945q8rdtq0rldhjfw0000gn/T/ipykernel_5889/2414119697.py:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import constants # create your own constants.py file to store api keys\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or 'OPENAI_API_KEY'\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# initialize LLM (we use ChatOpenAI because we'll later define a `chat` agent)\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0.6,\n",
    "    model_name='gpt-4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "# initialize conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity setup\n",
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "class GetClientDetails(BaseTool):\n",
    "    name: str = \"Client details extractor\"\n",
    "    description: str = \"use this tool when you have given a platform name, idea or platform link and you want to find more information about CEO of platform and proposed idea\"\n",
    "\n",
    "    def _run(self, website: str):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"pplx-70b-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are artificial intelligence agent which extracts an information by searching about it online\"\n",
    "                        \"and returns information in this format if it exists\"\n",
    "                        \"Title of website or platform: \"\n",
    "                        \"Proposed idea:\"\n",
    "                        \"CEO Information:\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"I am giving you platform name,idea or platform link and you have to find latest information about\" \n",
    "                        \"the platform by going to given link and return atleast 200 words description about idea and\"\n",
    "                        \"atleast 150 words description about CEO, their goal and achievements\"\n",
    "                        \"Please try to make it as detailed as you can and always refer to online information\"\n",
    "                        \"here is the platform link or name \"\n",
    "                        f\"{str(website)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {os.environ['PERPLEXITY_API_KEY']}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import os\n",
    "\n",
    "class GetPlatformInfo(BaseTool):\n",
    "    name: str = \"Platform info extractor\"\n",
    "    description: str = \"use this tool when you have given a description about a meeting, and you have to find the proposed idea, client name, or platform link from the given description\"\n",
    "\n",
    "    def _run(self, description: str):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"pplx-70b-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have been given a meeting description, and you need to find the proposed idea, client name, and website link mentioned in the given description. \"\n",
    "                        \"Use client info extractor tool to get more information. \"\n",
    "                        \"Return it in this format: \"\n",
    "                        \"Idea: <idea> \"\n",
    "                        \"Client Info: <client_info> \"\n",
    "                        \"Platform Link: <platform_link> \"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"If anything is not provided in the description, use internet and Google search to find the actual information. \"\n",
    "                        \"Here is the meeting description: \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {os.environ['PERPLEXITY_API_KEY']}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "\n",
    "    def _arun(self, website: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import os\n",
    "\n",
    "class GetIdeaSolution(BaseTool):\n",
    "    name: str = \"Solution extractor\"\n",
    "    description: str = \"use this tool when you have given an idea description and information about client and you have to find solution on how we can achieve the given idea\"\n",
    "\n",
    "    def _run(self, description: str):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"pplx-70b-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have been given an idea description and you have to find around 3-4 solutions to achieve the given idea using AI-ML \"\n",
    "                        \"or web development technologies. Search online about tech stack, resources, timeline of project, and YouTube videos, and send it with proper formatting and line breaks in this format: \"\n",
    "                        \"Solution: <solution> \"\n",
    "                        \"Tech stack: <tech_stack> \"\n",
    "                        \"Timeline: <timeline> \"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Here is the idea description: {str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {os.environ['PERPLEXITY_API_KEY']}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "\n",
    "    def _arun(self, website: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/r2n9ckp945q8rdtq0rldhjfw0000gn/T/ipykernel_5889/1189561063.py:4: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Creating Agent\n",
    "from langchain.agents import initialize_agent\n",
    "tools = [GetClientDetails(),GetPlatformInfo(),GetIdeaSolution()]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to extract the proposed idea, client name, and platform link from the given meeting description.\n",
      "Action: Platform info extractor\n",
      "Action Input: Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<Response [400]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe Platform info extractor tool didn't return any results. It seems like there's no platform link included in the description. However, the client's name \"Rohan\" and the idea of making a \"Twitter automation tool\" were mentioned.\n",
      "Action: Client details extractor\n",
      "Action Input: Rohan, Twitter automation tool\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m<Response [400]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe Client details extractor tool also didn't return any results. It seems the tool couldn't find more information about the CEO and proposed idea based on the given input.\n",
      "Action: Platform info extractor\n",
      "Action Input: Twitter automation tool\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<Response [400]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: The tools encountered issues while trying to retrieve information. As a result, I was unable to provide detailed information about the CEO, the proposed idea, and the solution. The available information from the initial question is that the client's name is Rohan and the proposed idea is to make a Twitter automation tool. However, the CEO's detailed information, the detailed proposal of the idea, and the solution were not found.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent Response: {'input': 'First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 wordsfetch realtime data from internet everytimeThis information is going to be added in project proposal so please write in detail and sections like CEO_Info,idea and solution must be explained in 600 words each.Return your response in python dict format like below and please use proper line breaks: \\n    \"platform_name\": platform_name\\n    \"CEO_Name\": ceo_name\\n    \"idea\": idea\\n    \"solution\": solution\\n    \"tech_stack\": tech stack\\n    \"timeline\": timeline\\n    \"Platform_link\": platform_link\\n    Here is the description:Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc', 'chat_history': [HumanMessage(content='First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 wordsfetch realtime data from internet everytimeThis information is going to be added in project proposal so please write in detail and sections like CEO_Info,idea and solution must be explained in 600 words each.Return your response in python dict format like below and please use proper line breaks: \\n      \"platform_name\": platform_name\\n      \"CEO_Name\": ceo_name\\n      \"idea\": idea\\n      \"solution\": solution\\n      \"tech_stack\": tech stack\\n      \"timeline\": timeline\\n      \"Platform_link\": platform_link\\n      Here is the description:Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Client's name: Rohan, Idea: Making a Twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides, etc. Platform link: Not provided in the description.\", additional_kwargs={}, response_metadata={})], 'output': \"The tools encountered issues while trying to retrieve information. As a result, I was unable to provide detailed information about the CEO, the proposed idea, and the solution. The available information from the initial question is that the client's name is Rohan and the proposed idea is to make a Twitter automation tool. However, the CEO's detailed information, the detailed proposal of the idea, and the solution were not found.\"}\n"
     ]
    }
   ],
   "source": [
    "para = agent(\n",
    "    \"First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words\"\n",
    "    \"fetch realtime data from internet everytime\"\n",
    "    \"This information is going to be added in project proposal so please write in detail and sections like CEO_Info,idea and solution must be explained in 600 words each.\"\n",
    "    \"Return your response in python dict format like below and please use proper line breaks: \"\n",
    "    \"\"\"\n",
    "    \"platform_name\": platform_name\n",
    "    \"CEO_Name\": ceo_name\n",
    "    \"idea\": idea\n",
    "    \"solution\": solution\n",
    "    \"tech_stack\": tech stack\n",
    "    \"timeline\": timeline\n",
    "    \"Platform_link\": platform_link\n",
    "    \"\"\"\n",
    "    \"Here is the description:\"\n",
    "    \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\n",
    ")\n",
    "\n",
    "# Print the raw response to see what's returned\n",
    "print(\"Agent Response:\", para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw GPT-4 Response: Here is the updated information in the Python dictionary format:\n",
      "\n",
      "```python\n",
      "project_info = {\n",
      "    'platform_name': 'Twitter Automation Tool',\n",
      "    'CEO_Info': 'Rohan is a proficient software engineer with over 10 years of experience in the field. He has a bachelor’s degree in Computer Science from the Indian Institute of Technology (IIT) and a master’s degree in Computer Science from Stanford University. Before founding this platform, he worked with major tech giants like Google and Microsoft. His area of expertise lies in automation and machine learning. He has a deep understanding of social media platforms and their APIs which led him to the creation of this Twitter Automation Tool.',\n",
      "    'CEO_Name': 'Rohan',\n",
      "    'idea': 'The idea is to create a Twitter automation tool. The tool will automate several tasks such as scheduling tweets, following and unfollowing users, retweeting, replying to tweets, and so on. This will help businesses and individuals to manage their Twitter accounts more efficiently. The tool will also include analytics to track the performance of the tweets and the account.',\n",
      "    'solution': 'The automation tool will be created using Python. Python has several libraries such as Tweepy and Python-twitter which can be used to interact with Twitter’s API. A user-friendly dashboard will be created where users can schedule their tweets, manage followers, and so on. For analytics, machine learning algorithms will be used to analyze the performance of the tweets and the account. The tool will also include features to automatically reply to tweets based on certain keywords. This can be achieved by implementing Natural Language Processing (NLP).',\n",
      "    'tech_stack': 'Python, Tweepy, Python-twitter, Machine learning, Natural Language Processing (NLP), Django for building the dashboard, PostgreSQL for database',\n",
      "    'timeline': 'The project is expected to take around 6 to 8 months. The first couple of months will be spent on research and planning. The next few months will be spent on the development of the tool. The final couple of months will be spent on testing and refining the tool.',\n",
      "    'Platform_link': 'Link to the platform will be provided once the development is complete.'\n",
      "    }\n",
      "```\n",
      "Please note that the above information is fictitious and is based on the initial information provided. The actual details may vary.\n",
      "Error: The response is not valid JSON. Here's the raw output:\n",
      "Here is the updated information in the Python dictionary format:\n",
      "\n",
      "```python\n",
      "project_info = {\n",
      "    'platform_name': 'Twitter Automation Tool',\n",
      "    'CEO_Info': 'Rohan is a proficient software engineer with over 10 years of experience in the field. He has a bachelor’s degree in Computer Science from the Indian Institute of Technology (IIT) and a master’s degree in Computer Science from Stanford University. Before founding this platform, he worked with major tech giants like Google and Microsoft. His area of expertise lies in automation and machine learning. He has a deep understanding of social media platforms and their APIs which led him to the creation of this Twitter Automation Tool.',\n",
      "    'CEO_Name': 'Rohan',\n",
      "    'idea': 'The idea is to create a Twitter automation tool. The tool will automate several tasks such as scheduling tweets, following and unfollowing users, retweeting, replying to tweets, and so on. This will help businesses and individuals to manage their Twitter accounts more efficiently. The tool will also include analytics to track the performance of the tweets and the account.',\n",
      "    'solution': 'The automation tool will be created using Python. Python has several libraries such as Tweepy and Python-twitter which can be used to interact with Twitter’s API. A user-friendly dashboard will be created where users can schedule their tweets, manage followers, and so on. For analytics, machine learning algorithms will be used to analyze the performance of the tweets and the account. The tool will also include features to automatically reply to tweets based on certain keywords. This can be achieved by implementing Natural Language Processing (NLP).',\n",
      "    'tech_stack': 'Python, Tweepy, Python-twitter, Machine learning, Natural Language Processing (NLP), Django for building the dashboard, PostgreSQL for database',\n",
      "    'timeline': 'The project is expected to take around 6 to 8 months. The first couple of months will be spent on research and planning. The next few months will be spent on the development of the tool. The final couple of months will be spent on testing and refining the tool.',\n",
      "    'Platform_link': 'Link to the platform will be provided once the development is complete.'\n",
      "    }\n",
      "```\n",
      "Please note that the above information is fictitious and is based on the initial information provided. The actual details may vary.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                I am giving you some data in python dict format and you will have to add more information by searching about it online in given data so that it can be added in project proposal but don't add any fake information. Once you got the information then return the data in the same format.\n",
    "                Try to add more information by yourself too to make it more detailed and make it around 1000 words. Don't return anything except this dictionary and also please use proper line breaks in every paragraph of each section of dict.\n",
    "                Here is the information about fields in the given dict: \n",
    "                platform_name: Name of platform\n",
    "                CEO_Info: Background about CEO and information about CEO\n",
    "                CEO_Name: Name of CEO\n",
    "                idea: project idea\n",
    "                solution: solution on how we can solve the given problem statement and how to achieve the given idea\n",
    "                tech_stack: tech stack used to build the solution\n",
    "                timeline: timeline for the project\n",
    "                Platform_link: link to the platform\n",
    "                Here is the data: \n",
    "                {para[\"output\"]}\n",
    "            \"\"\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Print the raw output\n",
    "print(\"Raw GPT-4 Response:\", chat_completion.choices[0].message.content)\n",
    "\n",
    "# Now let's safely try to parse the output as JSON\n",
    "try:\n",
    "    output = json.loads(chat_completion.choices[0].message.content)\n",
    "    print(\"Parsed Output:\", output)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: The response is not valid JSON. Here's the raw output:\")\n",
    "    print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Project Name\n",
      "Twitter Automation Tool\n",
      "\n",
      "# Who is the client?\n",
      "The client for this project is Rohan. Although we don't have much background information about Rohan, what we know is that he is an individual who is seeking to streamline his Twitter usage. He is forward-thinking, appreciates the power of automation, and understands the potential of leveraging technology to enhance productivity and efficiency.\n",
      "\n",
      "# What is the idea?\n",
      "Rohan's idea is to create a Twitter Automation Tool. This tool aims to automate certain repetitive tasks on Twitter to save time and improve efficiency. With the surge in the usage of social media platforms like Twitter, manually managing all the activities can be quite a daunting task. Rohan, understanding the potential of automation in this sphere, has proposed this idea. The tool could potentially automate tasks such as tweeting, retweeting, liking tweets, following/unfollowing users, and much more.\n",
      "\n",
      "# How can we help?\n",
      "To bring Rohan's idea to life, we would need to understand his specific requirements in detail. Based on the initial information, we can propose a solution that involves creating a web-based application that could be linked to a Twitter account. \n",
      "\n",
      "The application would leverage the Twitter API to perform various automated tasks. The user would be able to set specific conditions for automation, like keywords for auto-retweeting, time intervals for automated tweets, etc. The tool could also include analytics to track the effectiveness of the automation strategy.\n",
      "\n",
      "However, this is just a high-level solution, and the specifics would need to be worked out in detailed discussions with Rohan.\n",
      "\n",
      "# Tech Stack\n",
      "The tech stack for this project would primarily involve web development technologies. We anticipate using JavaScript with Node.js for backend development as it is efficient for handling API requests. For the frontend, we might use React.js as it allows for the creation of a dynamic and responsive user interface. \n",
      "\n",
      "We plan to use the Twitter API for interacting with Twitter, and MongoDB could be used as the database for storing user preferences and other data.\n",
      "\n",
      "# Timeline\n",
      "The timeline for this project would largely depend on the specific requirements and the complexity involved. A rough estimate could be anywhere from three to six months, including requirement gathering, design, development, testing, and deployment.\n",
      "\n",
      "# Additional Information\n",
      "Rohan's idea of a Twitter automation tool has great potential considering the increasing popularity of Twitter as a platform for personal branding, digital marketing, news dissemination, and much more. \n",
      "\n",
      "With proper execution, this tool can not only cater to individual users like Rohan but can also be scaled up to cater to businesses and digital marketing agencies.\n",
      "\n",
      "For more details about the platform, you can visit the following link: [Platform Link](Platform_link)\n"
     ]
    }
   ],
   "source": [
    "# Code for creating a markdown for our proposal\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                I am giving you some data in python dict format and you will have to add more information in it and convert it in markdown file with below format\n",
    "                Don't use anything except headings and paragraphs in markdown\n",
    "                # Project name\n",
    "                project name\n",
    "                # Who is the client?\n",
    "                information about client\n",
    "                # What is the idea?\n",
    "                information about idea\n",
    "                # How can we help?\n",
    "                detailed information about solution\n",
    "                # Tech stack\n",
    "                information about tech stack\n",
    "                # Timeline\n",
    "                information about timeline\n",
    "                Try to add more information by yourself too to make it more detailed and make it around 800 words. Don't return anything except markdown and use proper line breaks.\n",
    "                Here is the information about fields in the given dict: \n",
    "                platform_name: Name of platform\n",
    "                CEO_Info: Background about CEO and information about CEO\n",
    "                CEO_Name: Name of CEO\n",
    "                idea: project idea\n",
    "                solution: solution on how we can solve the given problem statement and how to achieve the given idea\n",
    "                tech_stack: tech stack used to build the solution\n",
    "                timeline: timeline for the project\n",
    "                Platform_link: link to the platform\n",
    "                Here is the data: \n",
    "                {para[\"output\"]}\n",
    "            \"\"\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")\n",
    "output = chat_completion.choices[0].message.content\n",
    "print(output)\n",
    "# output = json.loads(output)\n",
    "# print(json_output[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pypandoc in /Users/prasenjeetsmac/Library/Python/3.9/lib/python/site-packages (1.13)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pypandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No pandoc was found: either install pandoc and add it\nto your PATH or or call pypandoc.download_pandoc(...) or\ninstall pypandoc wheels with included pandoc.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpypandoc\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpypandoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.docx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# output = json.loads(output.output)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pypandoc/__init__.py:92\u001b[0m, in \u001b[0;36mconvert_text\u001b[0;34m(source, to, format, extra_args, encoding, outputfile, filters, verify_format, sandbox, cworkdir)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts given `source` from `format` to `to`.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m:param str source: Unicode string or bytes (see encoding)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m        path.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m source \u001b[38;5;241m=\u001b[39m _as_unicode(source, encoding)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstring\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverify_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msandbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msandbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcworkdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcworkdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pypandoc/__init__.py:364\u001b[0m, in \u001b[0;36m_convert_input\u001b[0;34m(source, format, input_type, to, extra_args, outputfile, filters, verify_format, sandbox, cworkdir)\u001b[0m\n\u001b[1;32m    361\u001b[0m _check_log_handler()\n\u001b[1;32m    363\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsuring pandoc path...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 364\u001b[0m \u001b[43m_ensure_pandoc_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_format:\n\u001b[1;32m    367\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVerifying format...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pypandoc/__init__.py:797\u001b[0m, in \u001b[0;36m_ensure_pandoc_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    789\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;124m    See http://johnmacfarlane.net/pandoc/installing.html\u001b[39m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124m    for installation options\u001b[39m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m))\n\u001b[1;32m    793\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;124m    ---------------------------------------------------------------\u001b[39m\n\u001b[1;32m    795\u001b[0m \n\u001b[1;32m    796\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m))\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo pandoc was found: either install pandoc and add it\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    798\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto your PATH or or call pypandoc.download_pandoc(...) or\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    799\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall pypandoc wheels with included pandoc.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: No pandoc was found: either install pandoc and add it\nto your PATH or or call pypandoc.download_pandoc(...) or\ninstall pypandoc wheels with included pandoc."
     ]
    }
   ],
   "source": [
    "import pypandoc\n",
    "output = pypandoc.convert_text(output, 'docx', format='md', outputfile=\"output.docx\")\n",
    "# output = json.loads(output.output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to gather information about the company Emerson Electric and their proposed idea, then I need to find a solution on how we can help them achieve this goal.\n",
      "Action: Client details extractor\n",
      "Action Input: Emerson Electric\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m<Response [400]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe client details extractor did not work. I need to try a different approach to gather information about Emerson Electric and their proposed idea.\n",
      "Action: Platform info extractor\n",
      "Action Input: Emerson Electric AI Manufacturing Process\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<Response [400]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe platform info extractor also did not work. I may need to manually research the information about Emerson Electric and their AI Manufacturing Process proposal.\n",
      "Action: Manual research\n",
      "Action Input: Emerson Electric, AI Manufacturing Process\u001b[0m\n",
      "Observation: Manual research is not a valid tool, try one of [Client details extractor, Platform info extractor, Solution extractor].\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: I'm sorry, the provided tools don't seem to be able to extract the required information for Emerson Electric and their AI Manufacturing Process proposal. I recommend manually researching the information needed for this project proposal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m para \u001b[38;5;241m=\u001b[39m agent(\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    First, gather information about the company Emerson Electric and their idea about implementing an AI-driven manufacturing process to enhance operational efficiency. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "para = agent(\n",
    "    \"\"\"\n",
    "    First, gather information about the company Emerson Electric and their idea about implementing an AI-driven manufacturing process to enhance operational efficiency. \n",
    "    Then, provide solutions on how we can help them achieve this goal, including technologies and strategies that can be used.\n",
    "    Please generate a professional project proposal including the following sections: \n",
    "    1. Client Information (Emerson Electric) \n",
    "    2. Idea (AI Manufacturing Process) \n",
    "    3. Potential Solutions for Enhancing Operational Efficiency \n",
    "    4. Tech Stack \n",
    "    5. Timeline\n",
    "    Please write this information in detail and return it in Python dictionary format.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "output = json.loads(para[\"output\"])\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
